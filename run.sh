ml cuDNN/8.7.0.84-CUDA-11.8.0
ml proxy
CUDA_VISIBLE_DEVICES="${1:-0}" python infer.py